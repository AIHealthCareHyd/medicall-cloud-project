<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Prudence Health Assistant</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://unpkg.com/react@18/umd/react.development.js"></script>
    <script src="https://unpkg.com/react-dom@18/umd/react-dom.development.js"></script>
    <script src="https://unpkg.com/@babel/standalone/babel.min.js"></script>
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css" rel="stylesheet">
</head>
<body class="bg-gray-100">

    <div id="root"></div>

    <script type="text/babel">
        const { useState, useEffect, useRef } = React;

        function App() {
            const [conversation, setConversation] = useState([
                { role: 'model', text: "నమస్కారం! నేను సహాయ్, మీ AI ఆరోగ్య సహాయకుడిని. నేను మీకు ఎలా సహాయపడగలను?" }
            ]);
            const [status, setStatus] = useState('idle');
            const [isListeningActive, setIsListeningActive] = useState(false);
            const [inputText, setInputText] = useState('');
            
            const recognitionRef = useRef(null);
            const conversationEndRef = useRef(null);
            const audioRef = useRef(null); // Ref to control the audio element

            const scrollToBottom = () => {
                conversationEndRef.current?.scrollIntoView({ behavior: "smooth" });
            };

            useEffect(() => {
                scrollToBottom();
            }, [conversation]);

            // --- REWRITTEN SPEAK FUNCTION ---
            // This now calls our secure backend function to get the audio.
            const speak = async (text) => {
                if (!text || status === 'speaking') return; // Prevent empty requests or overlaps
                setStatus('speaking');
                try {
                    const ttsFunctionUrl = 'https://sahayhealth.netlify.app/.netlify/functions/textToSpeech';
                    const response = await fetch(ttsFunctionUrl, {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify({ text }),
                    });

                    if (!response.ok) {
                        throw new Error(`Text-to-speech service failed with status ${response.status}`);
                    }

                    const data = await response.json();
                    if (data.audioContent) {
                        const audioSrc = `data:audio/mp3;base64,${data.audioContent}`;
                        if (audioRef.current) {
                            audioRef.current.src = audioSrc;
                            await audioRef.current.play();
                        }
                    } else {
                        throw new Error("No audio content received from the server.");
                    }
                } catch (error) {
                    console.error("Error playing synthesized speech:", error);
                    setStatus('idle'); // Reset status on error
                }
            };
            
            const getAiReply = async (currentConversation) => {
                setStatus('thinking');
                const historyForApi = currentConversation.map(turn => ({
                    role: turn.role,
                    parts: [{ text: turn.text }]
                }));

                const functionUrl = 'https://sahayhealth.netlify.app/.netlify/functions/getAiResponse';

                try {
                    const response = await fetch(functionUrl, {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify({ history: historyForApi }),
                    });

                    if (!response.ok) {
                        const errorData = await response.json();
                        throw new Error(`Network error: ${response.status} - ${errorData.error || response.statusText}`);
                    }

                    const data = await response.json();
                    const aiReplyText = data.reply || "క్షమించండి, నాకు అర్థం కాలేదు.";
                    
                    setConversation(prev => [...prev, { role: 'model', text: aiReplyText }]);
                    await speak(aiReplyText);
                    
                } catch (error) {
                    console.error("Error fetching AI response:", error);
                    const errorText = `An error occurred: ${error.message}`;
                    setConversation(prev => [...prev, { role: 'model', text: errorText }]);
                    await speak("క్షమించండి, ఒక లోపం సంభవించింది.").catch(e => console.error("Error speaking the error message:", e));
                }
            };

            const handleTextSubmit = (e) => {
                e.preventDefault();
                const trimmedInput = inputText.trim();
                if (!trimmedInput) return;
                const newConversation = [...conversation, { role: 'user', text: trimmedInput }];
                setConversation(newConversation);
                setInputText('');
                getAiReply(newConversation);
            };

            const toggleListening = () => {
                if (isListeningActive) {
                    recognitionRef.current?.stop();
                } else {
                    setStatus('listening');
                    try {
                        recognitionRef.current?.start();
                    } catch(e) {
                        console.error("Error starting recognition:", e);
                        setStatus('idle');
                    }
                }
            };

            useEffect(() => {
                const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
                if (!SpeechRecognition) {
                    console.warn("Speech recognition not supported.");
                    return;
                }
                recognitionRef.current = new SpeechRecognition();
                recognitionRef.current.continuous = false;
                recognitionRef.current.interimResults = false;
                recognitionRef.current.lang = 'te-IN';
            }, []);

            useEffect(() => {
                const recognition = recognitionRef.current;
                if (!recognition) return;
                
                recognition.onstart = () => { setIsListeningActive(true); setStatus('listening'); };
                recognition.onend = () => { setIsListeningActive(false); setStatus('idle'); };
                recognition.onerror = (event) => { console.error("Speech recognition error:", event.error); };
                recognition.onresult = (event) => {
                    const transcript = event.results[0][0].transcript.trim();
                    if(transcript) {
                        setConversation(prev => {
                            const updatedConversation = [...prev, { role: 'user', text: transcript }];
                            getAiReply(updatedConversation);
                            return updatedConversation;
                        });
                    }
                };

                return () => {
                    if (recognitionRef.current) {
                        recognitionRef.current.onstart = null;
                        recognitionRef.current.onend = null;
                        recognitionRef.current.onerror = null;
                        recognitionRef.current.onresult = null;
                    }
                };
            }, []);

            useEffect(() => {
                if (audioRef.current) {
                    const handleAudioEnd = () => setStatus('idle');
                    audioRef.current.addEventListener('ended', handleAudioEnd);
                    return () => {
                        if (audioRef.current) {
                            audioRef.current.removeEventListener('ended', handleAudioEnd);
                        }
                    };
                }
            }, [audioRef.current]);

            return (
                <div className="flex flex-col items-center justify-center min-h-screen bg-gray-100 font-sans p-4">
                    <audio ref={audioRef} style={{ display: 'none' }} />
                    <div className="w-full max-w-md h-[80vh] flex flex-col bg-white rounded-lg shadow-xl">
                        <div className="text-center p-4 border-b">
                            <h1 className="text-2xl font-bold text-blue-900">PRUDENCE HOSPITALS</h1>
                            <p className="text-sm text-gray-500">AI Health Assistant</p>
                        </div>
                        <div className="flex-1 p-4 overflow-y-auto flex flex-col gap-3 border-t">
                            {conversation.map((turn, index) => (
                                <div key={index} className={`p-3 rounded-lg max-w-[85%] w-fit ${turn.role === 'user' ? 'bg-blue-500 text-white self-end' : 'bg-gray-200 text-gray-800 self-start'}`}>
                                    <p>{turn.text}</p>
                                </div>
                            ))}
                            <div ref={conversationEndRef} />
                        </div>
                        <div className="p-4 border-t">
                             { (status === 'thinking' || status === 'speaking' || status === 'listening') &&
                                <p className="text-center text-sm text-gray-500 mb-2 italic">
                                    {status === 'listening' ? 'వింటున్నారు...' : status === 'thinking' ? 'సహాయ్ ఆలోచిస్తున్నారు...' : 'సహాయ్ మాట్లాడుతున్నారు...'}
                                </p>
                             }
                            <form onSubmit={handleTextSubmit} className="flex items-center gap-2">
                                <input
                                    type="text"
                                    value={inputText}
                                    onChange={(e) => setInputText(e.target.value)}
                                    placeholder="మీ సందేశాన్ని టైప్ చేయండి..."
                                    className="flex-1 p-3 border rounded-full focus:outline-none focus:ring-2 focus:ring-blue-500"
                                    disabled={status !== 'idle'}
                                />
                                <button
                                    type="submit"
                                    className="bg-blue-500 text-white rounded-full w-12 h-12 flex items-center justify-center hover:bg-blue-600 disabled:bg-gray-400"
                                    disabled={status !== 'idle' || !inputText.trim()}
                                >
                                    <i className="fas fa-paper-plane"></i>
                                </button>
                                <button
                                    type="button"
                                    onClick={toggleListening}
                                    className={`${isListeningActive ? 'bg-red-500' : 'bg-green-500'} text-white rounded-full w-12 h-12 flex items-center justify-center hover:bg-opacity-90 disabled:bg-gray-400`}
                                    disabled={status === 'thinking' || status === 'speaking'}
                                >
                                    <i className={`fas ${isListeningActive ? 'fa-stop' : 'fa-microphone'}`}></i>
                                </button>
                            </form>
                        </div>
                    </div>
                </div>
            );
        }

        const container = document.getElementById('root');
        const root = ReactDOM.createRoot(container);
        root.render(<App />);
    </script>

</body>
</html>

