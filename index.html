<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Prudence Health Assistant</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://unpkg.com/react@18/umd/react.development.js"></script>
    <script src="https://unpkg.com/react-dom@18/umd/react-dom.development.js"></script>
    <script src="https://unpkg.com/@babel/standalone/babel.min.js"></script>
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css" rel="stylesheet">
</head>
<body class="bg-gray-100">

    <div id="root"></div>

    <script type="text/babel">
        const { useState, useEffect, useRef } = React;

        function App() {
            const [conversation, setConversation] = useState([
                { role: 'model', text: "Welcome to Prudence Hospitals. I'm Sahay, your AI assistant. How can I help you today?" }
            ]);
            const [status, setStatus] = useState('idle'); // idle, listening, thinking, speaking
            const [isListeningActive, setIsListeningActive] = useState(false);
            const [inputText, setInputText] = useState('');
            
            const [voiceStatus, setVoiceStatus] = useState('loading'); // loading, ready, unavailable
            const [debugInfo, setDebugInfo] = useState(''); // To store debug messages
            const teluguVoiceRef = useRef(null); 
            
            const recognitionRef = useRef(null);
            
            const conversationEndRef = useRef(null);

            const scrollToBottom = () => {
                conversationEndRef.current?.scrollIntoView({ behavior: "smooth" });
            };

            useEffect(() => {
                scrollToBottom();
            }, [conversation]);

            const speak = (text) => {
                if (voiceStatus !== 'ready' || !teluguVoiceRef.current) {
                    console.warn("Speech cancelled: Telugu voice not available.");
                    return Promise.resolve();
                }

                window.speechSynthesis.cancel();
                return new Promise((resolve, reject) => {
                    setStatus('speaking');
                    const utterance = new SpeechSynthesisUtterance(text);
                    utterance.voice = teluguVoiceRef.current;
                    
                    utterance.onend = () => {
                        setStatus('idle');
                        resolve();
                    };
                    utterance.onerror = (event) => {
                        console.error("SpeechSynthesis Error", event);
                        setStatus('idle');
                        reject(event.error);
                    };
                    window.speechSynthesis.speak(utterance);
                });
            };
            
            const getAiReply = async (currentConversation) => {
                setStatus('thinking');
                
                const historyForApi = currentConversation.map(turn => ({
                    role: turn.role,
                    parts: [{ text: turn.text }]
                }));

                const functionUrl = 'https://sahayhealth.netlify.app/.netlify/functions/getAiResponse';

                try {
                    const response = await fetch(functionUrl, {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify({ history: historyForApi }),
                    });

                    if (!response.ok) {
                        const errorData = await response.json();
                        throw new Error(`Network error: ${response.status} - ${errorData.error || response.statusText}`);
                    }

                    const data = await response.json();
                    
                    const aiReplyEnglish = data.reply?.english || "Sorry, I had trouble understanding that.";
                    const aiReplyTelugu = data.reply?.telugu || aiReplyEnglish;
                    
                    setConversation(prev => [...prev, { role: 'model', text: aiReplyEnglish }]);
                    
                    await speak(aiReplyTelugu);
                    
                } catch (error) {
                    console.error("Error fetching AI response:", error);
                    const errorText = `There was an error: ${error.message}`;
                    setConversation(prev => [...prev, { role: 'model', text: errorText }]);
                    if (voiceStatus === 'ready') {
                       await speak("Sorry, an error occurred.").catch(e => console.error("Error speaking the error message:", e));
                    }
                }
            };

            const handleTextSubmit = (e) => {
                e.preventDefault();
                const trimmedInput = inputText.trim();
                if (!trimmedInput) return;
                const newConversation = [...conversation, { role: 'user', text: trimmedInput }];
                setConversation(newConversation);
                setInputText('');
                getAiReply(newConversation);
            };

            const toggleListening = () => {
                const currentlyActive = !isListeningActive;
                setIsListeningActive(currentlyActive);
                if (currentlyActive) {
                    recognitionRef.current?.start();
                } else {
                    recognitionRef.current?.stop();
                }
            };

            useEffect(() => {
                const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
                if (!SpeechRecognition) {
                    console.warn("Speech recognition not supported.");
                    return;
                }
                recognitionRef.current = new SpeechRecognition();
                recognitionRef.current.continuous = true;
                recognitionRef.current.interimResults = false;
                recognitionRef.current.lang = 'te-IN';
            }, []);

            useEffect(() => {
                const recognition = recognitionRef.current;
                if (!recognition) return;

                const handleResult = (event) => {
                    const transcript = event.results[event.results.length - 1][0].transcript.trim();
                    if(transcript) {
                        recognition.stop();
                        setConversation(prev => {
                            const updatedConversation = [...prev, { role: 'user', text: transcript }];
                            getAiReply(updatedConversation);
                            return updatedConversation;
                        });
                    }
                };

                const handleEnd = () => {
                    if (isListeningActive && status !== 'thinking' && status !== 'speaking') {
                        try { recognition.start(); } catch (e) { setStatus('idle'); }
                    } else if (!isListeningActive) {
                        setStatus('idle');
                    }
                };

                const handleError = (event) => {
                    console.error("Speech recognition error:", event.error);
                    if (event.error !== 'no-speech' && event.error !== 'aborted') { setStatus('idle'); }
                };

                const handleStart = () => setStatus('listening');

                recognition.onstart = handleStart;
                recognition.onresult = handleResult;
                recognition.onend = handleEnd;
                recognition.onerror = handleError;

                return () => {
                    if (recognitionRef.current) {
                        recognitionRef.current.onstart = null;
                        recognitionRef.current.onend = null;
                        recognitionRef.current.onerror = null;
                        recognitionRef.current.onresult = null;
                    }
                };
            }, [isListeningActive, status]);

            // Enhanced voice loading with better debugging
            useEffect(() => {
                const loadAndSetVoice = () => {
                    const availableVoices = window.speechSynthesis.getVoices();
                    if (availableVoices.length > 0) {
                        console.log("Available voices found:", availableVoices.map(v => `${v.name} (${v.lang})`));
                        const voice = availableVoices.find(v => v.lang === 'te-IN');
                        if (voice) {
                            teluguVoiceRef.current = voice;
                            setVoiceStatus('ready');
                            setDebugInfo(''); // Clear debug info on success
                        } else {
                            setVoiceStatus('unavailable');
                            const voiceLangs = [...new Set(availableVoices.map(v => v.lang))].join(', ');
                            setDebugInfo(`Tip: Your browser has voices for: ${voiceLangs}. Check your OS or browser settings to add a 'te-IN' voice pack.`);
                        }
                        window.speechSynthesis.onvoiceschanged = null; // Stop listening after finding voices
                    }
                };
                
                // This event is the most reliable way to get voices.
                window.speechSynthesis.onvoiceschanged = loadAndSetVoice;
                
                // Also try to load them immediately in case they are already cached.
                loadAndSetVoice();
                
                // Set a timeout as a final fallback for browsers that don't fire the event reliably.
                const timer = setTimeout(() => {
                    if(voiceStatus === 'loading') {
                       loadAndSetVoice(); // Try one last time
                       if (voiceStatus === 'loading') { // If still loading, then it's unavailable
                           setVoiceStatus('unavailable');
                           setDebugInfo("Voice loading timed out. Please check browser speech synthesis settings.");
                       }
                    }
                }, 2500);

                return () => {
                    clearTimeout(timer);
                    window.speechSynthesis.onvoiceschanged = null;
                };
            }, []);

            const VoiceStatusIndicator = () => {
                if (voiceStatus === 'loading') {
                    return (
                        <div className="p-3 text-center text-sm bg-blue-100 text-blue-800">
                            <p><strong>Initializing voice features...</strong></p>
                        </div>
                    );
                }
                if (voiceStatus === 'unavailable') {
                    return (
                        <div className="p-3 text-center text-sm bg-yellow-100 text-yellow-800">
                            <p className="font-bold">Telugu Voice Unavailable</p>
                            <p className="text-xs mt-1">{debugInfo}</p>
                        </div>
                    );
                }
                 if (voiceStatus === 'ready') {
                    return (
                        <div className="p-3 text-center text-sm bg-green-100 text-green-800">
                           <p><strong>Telugu voice is ready.</strong></p>
                        </div>
                    );
                }
                return null;
            }

            return (
                <div className="flex flex-col items-center justify-center min-h-screen bg-gray-100 font-sans p-4">
                    <div className="w-full max-w-md h-[80vh] flex flex-col bg-white rounded-lg shadow-xl">
                        <div className="text-center p-4 border-b">
                            <h1 className="text-2xl font-bold text-blue-900">PRUDENCE HOSPITALS</h1>
                            <p className="text-sm text-gray-500">AI Health Assistant</p>
                        </div>
                        <VoiceStatusIndicator />
                        <div className="flex-1 p-4 overflow-y-auto flex flex-col gap-3 border-t">
                            {conversation.map((turn, index) => (
                                <div key={index} className={`p-3 rounded-lg max-w-[85%] w-fit ${turn.role === 'user' ? 'bg-blue-500 text-white self-end' : 'bg-gray-200 text-gray-800 self-start'}`}>
                                    <p>{turn.text}</p>
                                </div>
                            ))}
                            <div ref={conversationEndRef} />
                        </div>
                        <div className="p-4 border-t">
                             { (status === 'thinking' || status === 'speaking' || status === 'listening') &&
                                <p className="text-center text-sm text-gray-500 mb-2 italic">
                                    {status === 'listening' ? 'Listening...' : status === 'thinking' ? 'Sahay is thinking...' : 'Sahay is speaking...'}
                                </p>
                             }
                            <form onSubmit={handleTextSubmit} className="flex items-center gap-2">
                                <input
                                    type="text"
                                    value={inputText}
                                    onChange={(e) => setInputText(e.target.value)}
                                    placeholder="Type your message..."
                                    className="flex-1 p-3 border rounded-full focus:outline-none focus:ring-2 focus:ring-blue-500"
                                    disabled={status !== 'idle'}
                                />
                                <button
                                    type="submit"
                                    className="bg-blue-500 text-white rounded-full w-12 h-12 flex items-center justify-center hover:bg-blue-600 disabled:bg-gray-400"
                                    disabled={status !== 'idle' || !inputText.trim()}
                                >
                                    <i className="fas fa-paper-plane"></i>
                                </button>
                                <button
                                    type="button"
                                    onClick={toggleListening}
                                    className={`${isListeningActive ? 'bg-red-500' : 'bg-green-500'} text-white rounded-full w-12 h-12 flex items-center justify-center hover:bg-opacity-90 disabled:bg-gray-400`}
                                    disabled={status === 'thinking' || status === 'speaking'}
                                >
                                    <i className={`fas ${isListeningActive ? 'fa-stop' : 'fa-microphone'}`}></i>
                                </button>
                            </form>
                        </div>
                    </div>
                </div>
            );
        }

        const container = document.getElementById('root');
        const root = ReactDOM.createRoot(container);
        root.render(<App />);
    </script>

</body>
</html>

